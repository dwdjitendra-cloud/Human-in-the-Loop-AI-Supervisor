# Human-in-the-Loop AI Supervisor

AI receptionist that answers from a knowledge base, escalates unknowns to human supervisors, and learns approved answers back into the KB.

Live deployments
- Backend (Render): https://human-in-the-loop-ai-supervisor-0umh.onrender.com
- Frontend (Vercel): https://reception-ai-inky.vercel.app

Stack
- Backend: Node.js, Express, MongoDB (Mongoose)
- Frontend: React (Vite), Tailwind CSS
- Voice: OpenAI STT/TTS on server, browser STT/TTS fallback, LiveKit token endpoint

## Overview

The system acts as a production-ready AI receptionist for small businesses:
- Calls or chat questions go to an automated agent.
- Agent answers from the knowledge base (KB) and safe business defaults (hours, location, services, phone).
- Unknown questions are escalated as Help Requests for supervisors to resolve.
- When a supervisor adds an approved answer, it’s stored in the KB for future automation.

## Features

- Help Request lifecycle: Pending → Resolved (with answer) → Unresolved (by timeout)
- Supervisor dashboard (auth), knowledge base CRUD and search
- Agent flow: KB lookup → defaults → escalate; no fabricated answers
- Voice endpoints: TTS, STT→answer→TTS; browser STT/TTS fallback; LiveKit token route
- Webhook simulation endpoint for simple notifications
- CORS hardening, environment-driven config, clean logs

## System architecture

High-level flow:

```
Frontend (React/Vite)
   ├─ LiveVoice (browser STT/TTS fallback)
   ├─ Pages: Pending/Resolved, Knowledge Base, Login
   └─ Services → REST API (/api/*)

Backend (Express/MongoDB)
   ├─ Routes: help-requests, knowledge-base, supervisors, voice, livekit, webhook
   ├─ Services: aiAgent (KB + defaults + escalation), STT/TTS, timeout handler
   ├─ Controllers + Models (Mongoose)
   └─ Utils: logger, error handler, CORS

External
   ├─ OpenAI (STT/TTS)
   └─ LiveKit (signaling; token generated by backend)
```

## Project structure

```
Human-in-the-Loop AI Supervisor/
├─ backend/
│  ├─ package.json
│  └─ src/
│     ├─ server.js
│     ├─ config/db.js
│     ├─ controllers/
│     │  ├─ helpRequestController.js
│     │  ├─ knowledgeBaseController.js
│     │  └─ supervisorController.js
│     ├─ models/
│     │  ├─ HelpRequest.js
│     │  ├─ KnowledgeBase.js
│     │  └─ Supervisor.js
│     ├─ routes/
│     │  ├─ helpRequests.js
│     │  ├─ knowledgeBase.js
│     │  ├─ supervisors.js
│     │  └─ webhook.js
│     ├─ services/
│     │  ├─ aiAgent.js
│     │  ├─ escalation.js
│     │  ├─ livekitAgent.js
│     │  ├─ openaiService.js
│     │  ├─ textToSpeech.js
│     │  └─ timeoutHandler.js
│     └─ utils/{errorHandler.js, logger.js}
├─ frontend/
│  ├─ package.json
│  ├─ vite.config.js
│  └─ src/
│     ├─ App.jsx, main.jsx, index.css
│     ├─ components/{Navbar.jsx, RequestList.jsx, KnowledgeBaseList.jsx}
│     ├─ pages/{Login.jsx, PendingRequests.jsx, ResolvedRequests.jsx, KnowledgeBase.jsx, TestAI.jsx, LiveVoice.jsx}
│     └─ services/api.js
└─ docs & root configs (README.md, DEPLOYMENT.md, vite/ts/tailwind configs)
```

## REST API

Base URL: https://human-in-the-loop-ai-supervisor-0umh.onrender.com/api

Help Requests

| Method | Path                                   | Description                                   |
|--------|----------------------------------------|-----------------------------------------------|
| GET    | /help-requests                         | List all help requests                        |
| GET    | /help-requests/pending                 | List pending requests                          |
| GET    | /help-requests/resolved                | List resolved requests                         |
| GET    | /help-requests/unresolved              | List unresolved (timed out)                    |
| GET    | /help-requests/:id                     | Get one                                       |
| POST   | /help-requests                         | Create { customerName, question }             |
| POST   | /help-requests/:id/resolve            | Resolve { answer }                            |
| DELETE | /help-requests/:id                     | Delete                                         |
| POST   | /help-requests/simulate-livekit-call   | Simulate agent via LiveKit adapter            |

Knowledge Base

| Method | Path                         | Description                              |
|--------|------------------------------|------------------------------------------|
| GET    | /knowledge-base              | List entries                             |
| GET    | /knowledge-base/search?q=.. | Search                                    |
| GET    | /knowledge-base/:id         | Get one                                  |
| POST   | /knowledge-base             | Create { question, answer, tags? }       |
| PUT    | /knowledge-base/:id         | Update                                    |
| DELETE | /knowledge-base/:id         | Delete                                    |
| POST   | /knowledge-base/supervisor-answer | Save approved answer back to KB    |

Supervisors

| Method | Path            | Description                        |
|--------|-----------------|------------------------------------|
| POST   | /supervisors/register | Register                       |
| POST   | /supervisors/login    | Login (JWT)                   |
| GET    | /supervisors          | List supervisors              |
| GET    | /supervisors/:id      | Get one                       |

Agent & Voice

| Method | Path                 | Description                                                      |
|--------|----------------------|------------------------------------------------------------------|
| POST   | /simulate-call       | Text agent: { customerName, question } → { response }           |
| GET    | /voice/tts?text=..   | TTS test → audio (Content-Type audio/mpeg by default)           |
| POST   | /voice/reply         | Text in → text+audio out; { customerName, question, voice? }    |
| POST   | /voice/stt-respond   | Multipart: audio (webm/opus). Optional field: voice             |
| POST   | /livekit/token       | Issue LiveKit access token (body: { identity, roomName })       |
| GET    | /livekit/token       | Token (query: identity, roomName) for quick checks              |
| POST   | /livekit/simulate-call | Simulate via LiveKit service path                             |

Health

| Method | Path     | Description           |
|--------|----------|-----------------------|
| GET    | /health  | Server liveness check |

## Environment variables

Backend (.env)

```env
PORT=5000
NODE_ENV=production
MONGO_URI=mongodb://localhost:27017/human-in-loop-ai
ALLOW_NO_DB=1
JWT_SECRET=change-me

# OpenAI
OPENAI_API_KEY=your-openai-key
TTS_VOICE=verse # alloy/verse supported

# LiveKit
LIVEKIT_URL=wss://your-livekit.livekit.cloud
LIVEKIT_API_KEY=lk_api_key
LIVEKIT_API_SECRET=lk_api_secret

# CORS (comma-separated; supports wildcards like https://*.vercel.app)
CORS_ORIGIN=https://reception-ai-inky.vercel.app
```

Frontend (.env.local)

```env
# Prefer the deployed backend API URL
VITE_API_BASE_URL=https://human-in-the-loop-ai-supervisor-0umh.onrender.com/api
# LiveKit URL for client join
VITE_LIVEKIT_URL=wss://your-livekit.livekit.cloud
```

## Local development

Backend

```powershell
cd backend
npm install
copy .env.example .env
# Edit .env → set MONGO_URI, OPENAI_API_KEY, CORS_ORIGIN (include http://localhost:5173 for Vite dev)
npm start
```

Frontend

```powershell
cd frontend
npm install
"VITE_API_BASE_URL=http://localhost:5000/api" | Out-File -Encoding ascii .env.local
# Optionally set VITE_LIVEKIT_URL to use LiveKit from dev
npm run dev
```

## Quick tests (PowerShell)

```powershell
# Health
Invoke-RestMethod 'http://localhost:5000/api/health'

# Text agent
$body = @{ customerName = 'Alice'; question = 'What are your hours?' } | ConvertTo-Json
Invoke-RestMethod 'http://localhost:5000/api/simulate-call' -Method Post -Body $body -ContentType 'application/json'

# TTS test (server)
curl "http://localhost:5000/api/voice/tts?text=Hello%20there" -o tts.mp3

# LiveKit token (GET)
Invoke-RestMethod 'http://localhost:5000/api/livekit/token?identity=tester&roomName=salon-room'
```

## Voice handling

- Server speech path: STT (OpenAI) → agent → TTS (OpenAI). Endpoint: `/api/voice/stt-respond` (multipart: `audio` field; optional `voice`).
- Text path: `/api/voice/reply` synthesizes audio for the returned answer.
- Browser fallback: LiveVoice page uses `SpeechRecognition` + `speechSynthesis` when server speech is unavailable/rate-limited.
- LiveKit: Backend issues tokens via `/api/livekit/token`; client connects using `VITE_LIVEKIT_URL`.

## OpenAI API behavior: when it works vs when it doesn’t

This project uses OpenAI on the backend for both speech-to-text (STT) and text-to-speech (TTS). No OpenAI key is required in the browser.

When OpenAI is working (healthy and key is valid)
- STT: The frontend streams short opus chunks (webm/opus) to `/api/voice/stt-respond`. The server transcribes with OpenAI STT.
- Agent: The server runs agent logic (KB → defaults → escalate) against the transcript and returns the selected answer.
- TTS: The answer is synthesized server-side via OpenAI and returned as audio (MIME usually `audio/mpeg`). The UI plays it immediately.
- Benefits: lower CPU on the client, consistent voice quality, and uniform behavior across browsers/devices.

When OpenAI is not available (rate-limited, quota exhausted, invalid key, network issues)
- Degradation detection on the client watches server responses:
   - A "beep" tone with an empty transcript, or
   - The safe fallback phrase: “Let me check with my supervisor and get back to you.”
- After a short warm-up period (about 6 seconds), if 3 degradations occur, the app temporarily switches to browser STT/TTS:
   - Browser STT: Web Speech API `SpeechRecognition` for transcription.
   - Browser TTS: `speechSynthesis` for audio playback.
   - A gentle, throttled hint appears: “I didn’t catch that — please repeat or type your question.”
- The client runs a periodic probe in the background; when server STT/TTS recover, it automatically switches back to the server path.
- Safety is preserved at all times: if the agent isn’t confident, it escalates to a supervisor rather than hallucinating.

Common symptoms and what the app does
- Rate limit/quota exceeded: temporary switch to browser STT/TTS; auto-recover later.
- Wrong/OpenAI key missing: server responds with errors; browser fallback continues to work; text input path still works.
- Unstable mic or quiet input: browser shows a brief hint and keeps recognition alive; typed fallback is always available.

Environment requirements
- Backend: set `OPENAI_API_KEY` and optionally `TTS_VOICE` (e.g., `verse`, `alloy`).
- Frontend: none needed for OpenAI; the browser fallback uses built-in APIs.
- If you deploy without an OpenAI key, the browser fallback path will still let you demo the agent using text/voice locally.

## Deployment (Render + Vercel)

Backend (Render)
- Create a Web Service pointing to `backend` folder; auto start command from package.json.
- Set env vars (see above). Health check: `/api/health`.
- Set `CORS_ORIGIN` to your Vercel domains (supports comma list and wildcards like `https://*.vercel.app`).

Frontend (Vercel)
- Project root: `frontend`. Set `VITE_API_BASE_URL` to your Render API (e.g., `https://<render>.onrender.com/api`).
- Optionally, include `frontend/vercel.json` with rewrites to proxy relative routes to Render.
- Set `VITE_LIVEKIT_URL` if using LiveKit.

## Troubleshooting

- 404 from API on Vercel: ensure `VITE_API_BASE_URL` is set or rewrites in `frontend/vercel.json` map API paths to the Render domain.
- CORS errors: update backend `CORS_ORIGIN` to include the exact Vercel URL(s) or use wildcard patterns.
- Port conflicts locally: stop other services on 5000 or point `VITE_API_BASE_URL` to the deployed backend.
- Beep-only or frequent fallback: verify OpenAI key quota; the browser fallback continues to work without keys.
- LiveKit token errors: set `LIVEKIT_API_KEY/SECRET` on the backend and `VITE_LIVEKIT_URL` on the frontend.

## Future improvements

- Streaming TTS playback: chunked audio streaming for lower start latency.
- Partial-result handling: speak short confirmations while full answers load.
- Supervisor tools: confidence heatmap for KB matches and quick edit/merge operations.
- Observability: dashboard for fallback rates, KB hit ratios, and escalation causes.
- RBAC and audit: per-route roles; audit logs for KB edits and escalations.
- Offline-first browser STT: add wake-word and local VAD for ultra-low latency demos.
- Background jobs: prune old help requests and rotate logs automatically.

## Security

- Do not commit API keys. Prefer environment variables and per-environment secrets.
- Restrict `CORS_ORIGIN` in production to your domains only.
- JWT secrets should be long and rotated. Never expose LiveKit API secret to the client.

## License

MIT

## Contact
Developer: Jitendra Dodwadiya  
LinkedIn: https://www.linkedin.com/in/dwdjitendra/  
Portfolio: https://dwdjitendra-portfolio.vercel.app/
